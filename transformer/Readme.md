# Train a Transformer with Stochastic Gradient Push

This directory contains the code to reproduce the neural machine translation experiment reported in the paper
> Mido Assran, Nicolas Loizou, Nicolas Ballas, and Michael Rabbat, "Stochastic Gradient Push for Distributed Deep Learning," ICML 2019. [Official ICML version](http://proceedings.mlr.press/v97/assran19a.html) [arxiv version](https://arxiv.org/abs/1811.10792)

## Setup
This code is meant to be used on PyTorch 0.5 for multi-node training.
Check out the [PyTorch 0.5 version](https://github.com/facebookresearch/stochastic_gradient_push/tree/sgp_pytorch0.5) of this code and follow the instructions in the [README](https://github.com/facebookresearch/stochastic_gradient_push/blob/sgp_pytorch0.5/transformer/Readme.md).
